# IR_SearchEngine
در این فاز از پروژه به منظور ایجاد یک مدل بازیابی اطلاعات ساده نیاز است تا اسناد شاخص گذاری شوند تا در زمان دریافت پرسمان از شاخص معکوس برای بازیابی اسناد مرتبط استفاده شود. به طور خلاصه مراحل انجام این فاز از پروژه به شرح زیر می باشد.

    استخراج توکن
    ساخت شاخص معکوس
    پیاده سازی 5 قاعده همسان سازی
    اعمال یک ایده برای جلوگیری از تغییر داده در بخش همسان سازی
    حذف کلمات پرتکرار
    پاسخ دهی به پرسمان کاربر

در ادامه به شرح نحوه انجام هریک از مراحل می پردازیم.
شاخص گذاری اسناد

برای شاخص گذاری اسناد لازم است بخشهای زیر پیاده سازی شوند:

    واکشی اسناد
    استخراج توکن
    همسان ساز کلمات
    حذف کلمات پرتکرار

پس از آنکه محتوای تمامی اسناد را به صورت توکن استخراج کردید، توکن ها را به صورت یک شاخص معکوس ذخیره کنید. توجه داشته باشید که این شاخص گذاری نباید در زمان دریافت پرسمان کاربر انجام شود بلکه باید شاخص از قبل ذخیره شده باشد و در زمان پاسخ گویی به کاربر تنها از آن استفاده نمود. برای آنکه بتوانید درستی عملکرد خود را نشان دهید یک تابع آزمون برای این بخش تعریف نمایید تا با دریافت یک کلمه لیستی از شماره اسناد (شماره فایل) که شامل این کلمه بودند را به صورت مرتب نمایش دهد. دقت داشته باشید که در شاخص معکوس هم کلمات و هم شماره اسناد باید به صورت مرتب شده باشند.

همان طور که می دانید همسان سازی کلمات و حذف کلمات پرتکرار برای بهبود عملکرد موتور جستجو الزامی است. برای بخش همسان سازی قواعدی را در نظر بگیرید و بر روی توکن ها اعمال نمایید.لازم به ذکر است که وجود حداقل 5 قاعده برای همسانسازی الزامی است و سعی نمایید تنوع را در این قواعد داشته باشید. به طور مثال می توانید بر روی فعلها، حروف جمع، پیشوندها و پسوندها، شناسه ها و حروف بیانگر برتری مانند "تر" و "ترین" همسانسازی را اعمال نمایید.

گاهی اوقات همسان سازی ممکن است اطلاعاتی را از بین ببرد. به طور مثال اگر دو قاعده حذف "می" از ابتدای فعل ها و حذف شناسه مربوط به فعل ها را داشته باشیم دو کلمه زیر معادل می شوند.

میدانم ← دان ، میدان← دان

در نتیجه حداقل یک ایده برای جلوگیری از چنین اشتباهاتی در بخش همسان سازی خود به کار ببرید.

علاوه بر اقدامات بالا نیاز است تا کلمات پرتکرار را حذف نمایید. برای این مرحله می توانید لیستی از پرتکرارترین کلمات را استخراج کنید و از آن لیست استفاده نمایید و یا در زمان ساخت شاخص معکوس زمانی پرتکرارترین کلمات را بیابید.
پاسخ دهی به پرسمان کاربر

در این بخش با دریافت پرسمان کاربر باید بتوانید اسناد مرتبط با آن را به صورت دودویی بازیابی نمایید. پرسمان کاربر به دو صورت زیر می تواند باشد:

تک کلمه: تنها کافی است که لیست مربوط به آن را از روی دیکشنری بازیابی نمایید.

چند کلمه: در این بخش لیست فایلها باید بر اساس میزان ارتباط مرتب شده باشد. مرتبطترین سند، سندی است که تمام کلمات را داشته باشد.

به نکات تحویل توجه کنید

در این مرحله مدل بازیابی اطلاعات باید بتواند نتایج جستجو را بر اساس ارتباط آنها با پرسمان کاربر رتبه بندی کند. مدل بازیابی اطلاعات این کار را با مدلسازی اسناد در فضای برداری انجام میدهد. به این صورت که برای هر سند یک بردار عددی استخراج میشود که بازنمایی آن سند در فضای برداری است. سپس با داشتن یک پرسمان از کاربر ابتدا آن را به فضای برداری برده و سپس با استفاده از یک معیار شباهت مناسب، فاصله ی بردارعددی پرسمان را با تمام اسناد در فضای برداری محاسبه کرده و در نهایت نتایج خروجی را بر اساس شباهت مرتب سازی میکنیم. همچنین برای افزایش سرعت پاسخگویی مدل بازیابی اطلاعات روش های مختلفی به کار گرفته خواهد شد. جزئیات هر بخش به تفصیل در ادامه بیان شده است.
مدل سازی اسناد در فضای برداری

در مرحله قبل پس از استخراج توکن ها اطلاعات به صورت یک دیکشنری ذخیره شدند. در این بخش هدف بر آن است که اسناد در فضای برداری بازنمایی شوند. با استفاده از روش وزندهی 𝑡𝑓−𝑖𝑑𝑓 بردار عددی برای هر سند محاسبه خواهد شد و درنهایت هر سند به صورت یک بردار شامل وزن های تمام کلمات آن سند بازنمایی می شود. محاسبه ی وزن هر کلمه 𝑡 در یک سند 𝑑 با داشتن مجموعه ی تمام اسناد 𝐷 با استفاده از معادله ی زیر محاسبه میشود

t𝑓𝑖𝑑𝑓(𝑡,𝑑,𝐷) = 𝑡𝑓(𝑡,𝑑) × 𝑖𝑑𝑓(𝑡,𝐷) = (1+log(𝑓𝑡,𝑑)) × log(𝑁/𝑛𝑡)
پاسخ دهی به پرسمان در فضای برداری

با داشتن پرسمان کاربر، بردار مخصوص پرسمان را استخراج کنید. سپس با استفاده از معیار شباهت سعی کنید اسنادی را که بیشترین شباهت (کمترین فاصله) را به پرسمان ورودی دارند پیدا کنید. سپس آنها را به ترتیب شباهت نمایش دهید. معیارهای فاصله ی مختلف میتواند برای این کار در نظر گرفته شود که ساده ترین آنها شباهت کسینوسی بین بردارها است که زاویه ی بین آنها را محاسبه میکند. این معیار به صورت زیر تعریف میشود:

S𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦(𝑎,𝑏) = cos(𝜃) = (𝑎.𝑏)/(|𝑎||𝑏|)

در انتهای کار برای نمایش یک صفحه از نتایج پرسمان فقط کافیست 𝐾 سندی انتخاب شوند که بیشترین شباهت را به پرسمان داشتند. ساده ترین راه حل برای این کار مرتبسازی تمام اسناد براساس شباهتشان با پرسمان است که هزینه زمانی این کار از مرتبه ی (𝑂(𝑛𝑙𝑜𝑔𝑛 است که با فرض زیاد بودن تعداد اسناد میتواند باعث زیاد شدن شدید زمان پاسخ موتور جستجو شود. برای حل این مسئله از پشته (ℎ𝑒𝑎𝑝) استفاده کنید و برای نمایش هر صفحه تنها 𝐾 سند با بیشترین شباهت را از آن بیرون بکشید. توجه کنید که ساختن پشته از مرتبهی زمانی (𝑂(2𝑛 و استخراج 𝐾 سند با بیشترین مقدار از مرتبهی (𝑂(𝑙𝑜𝑔𝑛 است و در مجموع این تکنیک میتواند حدوداً مشکل زیاد بودن زمان پاسخ را حل کند. توجه کنید که اسناد با امتیاز صفر نیازی نیست در پشته ریخته شوند. شناسایی این اسناد و حذف آنها با استفاده از تکنیک 𝐼𝑛𝑑𝑒𝑥 𝑒𝑙𝑖𝑚𝑖𝑛𝑎𝑡𝑖𝑜𝑛 در مرحله اول انجام شده است.
افزایش سرعت پردازش پرسمان

با استفاده از تکنیک 𝐼𝑛𝑑𝑒𝑥 𝑒𝑙𝑖𝑚𝑖𝑛𝑎𝑡𝑖𝑜𝑛 تاحدودی مشکل زیاد بودن زمان در مراحل قبل حل شد اما همچنان زمان پاسخگویی برای بسیاری از کاربردها قابل قبول نمی باشد. برای آنکه سرعت پردازش و پاسخگویی افزایش یابد روش های مختلفی وجود دارند که یکی از آن روش ها روش 𝐶ℎ𝑎𝑚𝑝𝑖𝑜𝑛 𝑙𝑖𝑠𝑡𝑠 می باشد که قبل از آنکه پرسمانی مطرح شود و در مرحله پردازش اسناد، یک لیست از مرتبط ترین اسناد مربوط به هر 𝑡𝑒𝑟𝑚 در لیست جداگانه ای نگه داری می شوند. برای پیاده سازی این بخش پس از ساخت شاخص معکوس زمانی، 𝐶ℎ𝑎𝑚𝑝𝑖𝑜𝑛 𝑙𝑖𝑠𝑡 را ایجاد کنید و تنها بردار پرسمان را با بردار اسنادی که از طریق جستجو در 𝐶ℎ𝑎𝑚𝑝𝑖𝑜𝑛 𝑙𝑖𝑠𝑡 به دست آوردهاید مقایسه کنید و 𝐾 سند مرتبط را به نمایش بگذارید. توضیحات بیشتر این روش در فصل 7 کتاب آمده است.

نکته: می توانید وزن دهی 𝑡𝑓−𝑖𝑑𝑓 و ایجاد لیست 𝐶ℎ𝑎𝑚𝑝𝑖𝑜𝑛 را با استفاده از شاخص معکوس که در مرحله گذشته پیاده سازی کردهاید، انجام دهید و پس از آن بازنمایی اسناد به فضای برداری را انجام دهید
مجموعه داده

مجموعه داده مورد استفاده برای ارزیابی و تست دو فاز اول به صورت فایل های متنی در اختیار شما قرار می گیرد. هر فایل متنی شامل متن یک خبر است که شما به بررسی آنها می پردازید. نام هر فایل متنی یک عدد است که شما باید از آن به عنوان id فایل استفاده نمایید.

مطالب موجود در صفحات ویکی پدیا به طور دسته بندی شده و به زبان های مختلف در دسترس می باشند. درحال حاضر کتابخانه هایی وجود دارند که میتوانند داده های این صفحات را به زبانهای مختلف و در دسته بندی های مختلف استخراج نمایند. برای آنکه بتوانیم از خوشه بندی جهت بهبود عملکرد و سرعت موتور جستجو استفاده کنیم نیاز است تا تمامی اسناد را به فضای برداری ببریم و پس از آن الگوریتم های لازم را پیاده سازی نماییم. در این پروژه نیازی به اجرای الگوریتم های خوشه بندی اسناد نیست چرا که میتوان اسناد را بر اساس دسته بندیهای جداگانه آنها از ویکیپدیا به دست آورد و از همین دسته بندی به عنوان خوشه بندی اسناد استفاده کرد. برای شروع شما باید محتوای متن اصلی 55 صفحه از هرکدام از 5 دسته بندی زیر را به زبان فارسی استخراج نمایید:

    فیزیک
    ریاضیات
    سلامتی
    تاریخ
    تکنولوژی

حال که شما 5 خوشه را به طور آماده در دسترس دارید باید به محاسبه مراکز هر دسته بپردازید. برای انجام این کار نیاز است تا داده های مرحله قبل را به صورت بردار درآورید.(از کدهای فازهای قبل خود برای ساخت شاخص معکوس و بردار اسناد استفاده نمایید.) با انجام این مراحل شما باید اطلاعات زیر را داشته باشید:

    بازنمایی هر سند در فضای برداری + خوشهای که سند به آن تعلق دارد.
    مرکز هر خوشه به صورت برداری

پاسخ دهی پرسمان با استفاده از خوشه ها

در این مرحله برای پاسخ دهی به پرسمان کاربر تنها باید پرسمان را با مراکز هر خوشه مقایسه کنید و نزدیک ترین مرکز خوشه را پیدا کنید. پس از آن پرسمان را تنها با اسناد همان خوشه مقایسه نمایید و مرتبط ترین ها را به ترتیب بازگردانید. با اینکار علاوه بر افزایش سرعت، اسناد بازگردانده شده شباهت مفهومی بیشتری نیز دارند.
